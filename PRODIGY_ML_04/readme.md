# Gesture Recognition System

This project provides a system for recognizing hand gestures using a camera. It includes three main components: data collection, gesture recognition, and model training.

## Components

### 1. Data Collection (data_collect.py)

This script captures images of various hand gestures and saves them to a designated dataset directory. It utilizes OpenCV for video capture and MediaPipe for accurate hand landmark detection.

#### Dependencies:

- OpenCV
- MediaPipe
- NumPy

#### Usage:

1. Ensure your camera is connected.
2. Run the script using the following command:
    ```bash
    python data_collect.py
    ```
3. Follow the on-screen instructions to collect data for each gesture (e.g., open hand, closed fist, pointing finger, etc.).

### 2. Gesture Recognition (gesture_rec.py)

This script utilizes a pre-trained machine learning model to recognize hand gestures in real-time. It captures video from the camera, performs image processing on each frame to detect hand landmarks, and predicts the corresponding gesture.

#### Dependencies:

- OpenCV
- MediaPipe
- TensorFlow
- NumPy

#### Usage:

1. Ensure your camera is connected.
2. Place the pre-trained model file named `gesture_model.h5` in the same directory as the script.
3. Run the script using the following command:
    ```bash
    python gesture_rec.py
    ```
4. The video feed will be displayed with the recognized gestures overlaid on the screen.

### 3. Model Training (model_save.py)

This script empowers you to train a neural network model on the gesture data you've collected. It loads the gesture data, splits it into training and test sets for effective training, defines the model architecture, trains the model, and ultimately saves the trained model to a file for future use.

#### Dependencies:

- NumPy
- scikit-learn (optional, for data preprocessing)
- TensorFlow

#### Usage:

1. Ensure you have collected gesture data and stored it in the designated directory (dataset).
2. Run the script using the following command:
    ```bash
    python model_save.py
    ```
3. The trained model will be saved as `gesture_model.h5` in the same directory.

## Installation

To install the required dependencies, run the following command in your terminal:
```bash
pip install -r requirements.txt
```

## Directory Structure:
├── dataset/
│   ├── Open_Hand/        # Folder for open hand gesture images
│   ├── Closed_Fist/      # Folder for closed fist gesture images
│   ├── Pointing/         # Folder for pointing gesture images
│   ├── Peace_Sign/       # Folder for peace sign gesture images
│   ├── Thumbs_Up/        # Folder for thumbs up gesture images
│   └── OK_Sign/          # Folder for OK sign gesture images
├── data_collect.py
├── gesture_rec.py
├── model_save.py
└── gesture_model.h5      # Trained model file (generated by model_save.py)

##Contributing
We welcome contributions to this project! Feel free to fork the repository and submit pull requests. For more significant changes, please open an issue first to discuss your proposed modifications.
